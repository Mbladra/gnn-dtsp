{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from src.utils import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from graph_nets.demos import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loss_ops(target_op, output_ops):\n",
    "    loss_ops = [\n",
    "        tf.losses.softmax_cross_entropy(target_op.nodes, output_op.nodes) +\n",
    "        tf.losses.softmax_cross_entropy(target_op.edges, output_op.edges)\n",
    "        for output_op in output_ops\n",
    "    ]\n",
    "    return loss_ops\n",
    "\n",
    "# todo\n",
    "def compute_accuracy(target, output, use_nodes=True, use_edges=False):\n",
    "    correct = 1\n",
    "    solved = 1\n",
    "    return correct, solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/roger/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/roger/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/roger/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roger/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# Model Setup\n",
    "tf.reset_default_graph()\n",
    "\n",
    "seed = 2\n",
    "rand = np.random.RandomState(seed=seed)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 10\n",
    "num_processing_steps_ge = 10\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 10000\n",
    "theta = 20  # Large values (1000+) make trees. Try 20-60 for good non-trees.\n",
    "batch_size_tr = 32\n",
    "batch_size_ge = 100\n",
    "# Number of nodes per graph sampled uniformly from this range.\n",
    "num_nodes_min_max_tr = (8, 17)\n",
    "num_nodes_min_max_ge = (16, 33)\n",
    "\n",
    "# Data.\n",
    "# Input and target placeholders.\n",
    "input_ph, target_ph = create_placeholders(batch_size_tr)\n",
    "\n",
    "# Connect the data to the model.\n",
    "# Instantiate the model.\n",
    "model = models.EncodeProcessDecode(edge_output_size=2, node_output_size=2)\n",
    "# A list of outputs, one per processing step.\n",
    "output_ops_tr = model(input_ph, num_processing_steps_tr)\n",
    "output_ops_ge = model(input_ph, num_processing_steps_ge)\n",
    "\n",
    "# Training loss.\n",
    "loss_ops_tr = create_loss_ops(target_ph, output_ops_tr)\n",
    "# Loss across processing steps.e\n",
    "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
    "# Test/generalization loss.\n",
    "loss_ops_ge = create_loss_ops(target_ph, output_ops_ge)\n",
    "loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n",
    "\n",
    "# Optimizer.\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "step_op = optimizer.minimize(loss_op_tr)\n",
    "\n",
    "# Lets an iterable of TF graphs be output from a session as NP graphs.\n",
    "input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Session\n",
    "#@title Reset session  { form-width: \"30%\" }\n",
    "\n",
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 0\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# (iteration number), T (elapsed seconds), Ltr (training loss), Lge (test/generalization loss), Ctr (training fraction nodes/edges labeled correctly), Str (training fraction examples solved correctly), Cge (test/generalization fraction nodes/edges labeled correctly), Sge (test/generalization fraction examples solved correctly)\n",
      "# 00138, T 21.2, Ltr 0.4474, Lge 0.4526, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 00326, T 40.3, Ltr 0.4126, Lge 0.3995, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 00521, T 60.4, Ltr 0.3891, Lge 0.3942, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 00707, T 80.5, Ltr 0.4029, Lge 0.3949, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 00904, T 100.6, Ltr 0.3968, Lge 0.3903, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 01108, T 120.7, Ltr 0.3678, Lge 0.3446, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 01316, T 140.7, Ltr 0.3564, Lge 0.3525, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 01523, T 160.7, Ltr 0.3760, Lge 0.3564, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 01728, T 180.7, Ltr 0.3855, Lge 0.3375, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 01938, T 200.8, Ltr 0.3672, Lge 0.3545, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 02147, T 220.8, Ltr 0.3437, Lge 0.3317, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 02357, T 240.9, Ltr 0.3830, Lge 0.3221, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 02561, T 260.9, Ltr 0.3285, Lge 0.3347, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 02771, T 280.9, Ltr 0.3401, Lge 0.3287, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 02980, T 300.9, Ltr 0.3347, Lge 0.3506, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 03189, T 321.0, Ltr 0.3832, Lge 0.3351, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n",
      "# 03397, T 341.0, Ltr 0.3470, Lge 0.3378, Ctr 1.0000, Str 1.0000, Cge 1.0000, Sge 1.0000\n"
     ]
    }
   ],
   "source": [
    "#@title Run training  { form-width: \"30%\" }\n",
    "\n",
    "# You can interrupt this cell's training loop at any time, and visualize the\n",
    "# intermediate results by running the next cell (below). You can then resume\n",
    "# training by simply executing this cell again.\n",
    "\n",
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 20\n",
    "\n",
    "print(\"# (iteration number), T (elapsed seconds), \"\n",
    "      \"Ltr (training loss), Lge (test/generalization loss), \"\n",
    "      \"Ctr (training fraction nodes/edges labeled correctly), \"\n",
    "      \"Str (training fraction examples solved correctly), \"\n",
    "      \"Cge (test/generalization fraction nodes/edges labeled correctly), \"\n",
    "      \"Sge (test/generalization fraction examples solved correctly)\")\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "    last_iteration = iteration\n",
    "    feed_dict, _ = create_feed_dict(batch_size_tr, input_ph, target_ph)\n",
    "    train_values = sess.run({\n",
    "        \"step\": step_op,\n",
    "        \"target\": target_ph,\n",
    "        \"loss\": loss_op_tr,\n",
    "        \"outputs\": output_ops_tr\n",
    "    }, feed_dict=feed_dict)\n",
    "    the_time = time.time()\n",
    "    elapsed_since_last_log = the_time - last_log_time\n",
    "    if elapsed_since_last_log > log_every_seconds:\n",
    "        last_log_time = the_time\n",
    "        feed_dict, raw_graphs = create_feed_dict(batch_size_ge, input_ph, target_ph)\n",
    "        test_values = sess.run({\n",
    "            \"target\": target_ph,\n",
    "            \"loss\": loss_op_ge,\n",
    "            \"outputs\": output_ops_ge\n",
    "        },\n",
    "                           feed_dict=feed_dict)\n",
    "        correct_tr, solved_tr = compute_accuracy(\n",
    "            train_values[\"target\"], train_values[\"outputs\"][-1], use_edges=True)\n",
    "        correct_ge, solved_ge = compute_accuracy(\n",
    "            test_values[\"target\"], test_values[\"outputs\"][-1], use_edges=True)\n",
    "        elapsed = time.time() - start_time\n",
    "        losses_tr.append(train_values[\"loss\"])\n",
    "        corrects_tr.append(correct_tr)\n",
    "        solveds_tr.append(solved_tr)\n",
    "        losses_ge.append(test_values[\"loss\"])\n",
    "        corrects_ge.append(correct_ge)\n",
    "        solveds_ge.append(solved_ge)\n",
    "        logged_iterations.append(iteration)\n",
    "        print(\"# {:05d}, T {:.1f}, Ltr {:.4f}, Lge {:.4f}, Ctr {:.4f}, Str\"\n",
    "              \" {:.4f}, Cge {:.4f}, Sge {:.4f}\".format(\n",
    "                  iteration, elapsed, train_values[\"loss\"], test_values[\"loss\"],\n",
    "                  correct_tr, solved_tr, correct_ge, solved_ge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
